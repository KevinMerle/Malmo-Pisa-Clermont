{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42da47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82010814",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"Data/Mats_Shoes/summarytable.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24eb2b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Participant     Test type    Test Number      Start timestamp  \\\n",
      "0              NaN           NaN            NaN                  NaN   \n",
      "1    PhonesWatches           NaN            NaN                  NaN   \n",
      "2               DL  TUG - normal              1  2023-10-27T16:02:31   \n",
      "3               DL  TUG - normal              2  2023-10-27T16:03:47   \n",
      "4               DL    TUG - slow              3  2023-10-27T16:05:01   \n",
      "..             ...           ...            ...                  ...   \n",
      "169             RC         30SCS              5  2023-10-31T10:29:10   \n",
      "170             RC         30SCS              5  2023-10-31T10:29:10   \n",
      "171             RC           TUG  1, 2, 3 and 4  2023-10-31T10:22:09   \n",
      "172             RC           TUG  1, 2, 3 and 4  2023-10-31T10:22:09   \n",
      "173             RC           TUG  1, 2, 3 and 4  2023-10-31T10:22:09   \n",
      "\n",
      "           End timestamp                        Notes  \\\n",
      "0                    NaN                          NaN   \n",
      "1                    NaN                          NaN   \n",
      "2    2023-10-27T16:02:43  Start and end of hand phone   \n",
      "3    2023-10-27T16:03:57                          NaN   \n",
      "4    2023-10-27T16:05:24                          NaN   \n",
      "..                   ...                          ...   \n",
      "169  2023-10-31T10:29:50                     Floor 2    \n",
      "170  2023-10-31T10:29:50                         Seat   \n",
      "171  2023-10-31T10:26:19                      Floor 1   \n",
      "172  2023-10-31T10:26:19                     Floor 2    \n",
      "173  2023-10-31T10:26:19                         Seat   \n",
      "\n",
      "                                           Sensor type               Filename  \n",
      "0                                                  NaN                    NaN  \n",
      "1                                                  NaN                    NaN  \n",
      "2    motion / orientation/ accel/compass/steps/hear...  testResults_Dl01.json  \n",
      "3    motion/orientation/accel/compass/steps/heart rate  testResults_Dl02.json  \n",
      "4          motion/orientation/accel/compass/heart rate  testResults_Dl03.json  \n",
      "..                                                 ...                    ...  \n",
      "169                                           Pressure        RC_30SCR_Floor2  \n",
      "170                                           Pressure          RC_30SCR_Seat  \n",
      "171                                           Pressure          RC_TUG_Floor1  \n",
      "172                                           Pressure          RC_TUG_Floor2  \n",
      "173                                           Pressure            RC_TUG_Seat  \n",
      "\n",
      "[174 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a59dc",
   "metadata": {},
   "source": [
    "# Fichier en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408f6b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     DS_10+20M_Floor1\n",
      "1     DS_10+20M_Floor2\n",
      "2     DS_10+20M_Floor1\n",
      "3     DS_10+20M_Floor2\n",
      "4      DS_30SCS_Floor1\n",
      "            ...       \n",
      "60     RC_30SCR_Floor2\n",
      "61       RC_30SCR_Seat\n",
      "62       RC_TUG_Floor1\n",
      "63       RC_TUG_Floor2\n",
      "64         RC_TUG_Seat\n",
      "Name: Filename, Length: 65, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier Excel en sautant les lignes jusqu'à la ligne 110\n",
    "# et en chargeant les lignes de 111 à 175\n",
    "df = pd.read_excel('Data/Mats_Shoes/summarytable.xlsx', skiprows=range(1, 110), nrows=65)\n",
    "\n",
    "# Extraire les valeurs de la troisième colonne pour les lignes de 111 à 175\n",
    "valeurs_colonne = df.iloc[:, 7]\n",
    "\n",
    "# Afficher les valeurs de la troisième colonne\n",
    "print(valeurs_colonne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a515605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS_10+20M_Floor1\n"
     ]
    }
   ],
   "source": [
    "print(valeurs_colonne[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d4437",
   "metadata": {},
   "source": [
    "# Automatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d94a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6d2766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35    NaN\n",
      "Name: NomFichier, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ts=pd.read_csv(\"Data/Mats_Shoes/TS1.csv\")\n",
    "resultat=ts.loc[ts[\"Participant\"]==\"RC\"]\n",
    "print(resultat.loc[resultat[\"Test Number\"]==6][\"NomFichier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b0a28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1698411735000\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.0f}\".format(ts[\"Start timestamp\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c825022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "169841173500\n"
     ]
    }
   ],
   "source": [
    "a=ts['Start timestamp'][0]\n",
    "resultat = int(str(a)[:-3])\n",
    "print(type(ts[\"Test Number\"][0]))\n",
    "print(resultat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cb63d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5caf45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in ts.iterrows():\n",
    "    timestamp_deb_ent=\"{:.0f}\".format(row['Start timestamp'])\n",
    "    timestamp_deb = int(str(timestamp_deb_ent)[:-3])\n",
    "    timestamp_fin_ent=\"{:.0f}\".format(row['End timestamp'])\n",
    "    timestamp_fin = int(str(timestamp_fin_ent)[:-3])\n",
    "    part=row['Participant']\n",
    "    test=row['Test Number']\n",
    "    outil=[\"Floor1\",\"Floor2\",\"Seat\"]\n",
    "    fich=row['NomFichier']\n",
    "    if (fich!=0):\n",
    "        if (test==7 or test==8 or test==9 or test==10):\n",
    "            for out in outil[:-1]:\n",
    "                # Chemin vers le fichier CSV\n",
    "                chemin_fichier_csv = \"Data/Mats_Shoes/\"+fich+\"_\"+out+\".csv\"\n",
    "\n",
    "                # Charger le fichier CSV en utilisant Pandas\n",
    "                ds_acc = pd.read_csv(chemin_fichier_csv)\n",
    "                start01 = int(timestamp_deb)\n",
    "                end01 = int(timestamp_fin)\n",
    "                ds_acc_01 = ds_acc[ds_acc['Timestamp']>=(start01-5)]\n",
    "                ds_acc_01 = ds_acc_01[ds_acc_01['Timestamp']<=(end01+5)]\n",
    "                chemin_dossier = \"Results/\"+part+\"/\"+str(test)+\"/\"\n",
    "                nom_fichier = part+\"_mats_\"+out+\"_\"+str(test)+\".csv\"\n",
    "                chemin_sauvegarde = chemin_dossier + nom_fichier\n",
    "                ds_acc_01.to_csv(chemin_sauvegarde, index=False,header=False)\n",
    "        else:\n",
    "            if (part!=\"DS\" and part!=\"DL\"):\n",
    "                for out in outil:\n",
    "                    # Chemin vers le fichier CSV\n",
    "                    chemin_fichier_csv = \"Data/Mats_Shoes/\"+fich+\"_\"+out+\".csv\"\n",
    "\n",
    "                    # Charger le fichier CSV en utilisant Pandas\n",
    "                    ds_acc = pd.read_csv(chemin_fichier_csv)\n",
    "\n",
    "\n",
    "                    start01 = int(timestamp_deb)\n",
    "                    end01 = int(timestamp_fin)\n",
    "                    ds_acc_01 = ds_acc[ds_acc['Timestamp']>=(start01-5)]\n",
    "                    ds_acc_01 = ds_acc_01[ds_acc_01['Timestamp']<=(end01+5)]\n",
    "                    chemin_dossier = \"Results/\"+part+\"/\"+str(test)+\"/\"\n",
    "                    nom_fichier = part+\"_mats_\"+out+\"_\"+str(test)+\".csv\"\n",
    "                    chemin_sauvegarde = chemin_dossier + nom_fichier\n",
    "                    ds_acc_01.to_csv(chemin_sauvegarde, index=False,header=False)\n",
    "            else:\n",
    "                if (test==1 or test==2 or test==3 or test==4):\n",
    "                    for out in outil:\n",
    "                        chemin_fichier_csv = \"Data/Mats_Shoes/\"+fich+\"_\"+out+\".csv\"\n",
    "\n",
    "                        # Charger le fichier CSV en utilisant Pandas\n",
    "                        ds_acc = pd.read_csv(chemin_fichier_csv)\n",
    "\n",
    "\n",
    "                        start01 = int(timestamp_deb)\n",
    "                        end01 = int(timestamp_fin)\n",
    "                        ds_acc_01 = ds_acc[ds_acc['Timestamp']>=(start01-5)]\n",
    "                        ds_acc_01 = ds_acc_01[ds_acc_01['Timestamp']<=(end01+5)]\n",
    "                        chemin_dossier = \"Results/\"+part+\"/\"+str(test)+\"/\"\n",
    "                        nom_fichier = part+\"_mats_\"+out+\"_\"+str(test)+\".csv\"\n",
    "                        chemin_sauvegarde = chemin_dossier + nom_fichier\n",
    "                        ds_acc_01.to_csv(chemin_sauvegarde, index=False,header=False)\n",
    "                else :\n",
    "                    outils2=[outil[0],outil[2]]\n",
    "                    for out in outils2:\n",
    "                         # Chemin vers le fichier CSV\n",
    "                        chemin_fichier_csv = \"Data/Mats_Shoes/\"+fich+\"_\"+out+\".csv\"\n",
    "\n",
    "                        # Charger le fichier CSV en utilisant Pandas\n",
    "                        ds_acc = pd.read_csv(chemin_fichier_csv)\n",
    "\n",
    "                        start01 = int(timestamp_deb)\n",
    "                        end01 = int(timestamp_fin)\n",
    "                        ds_acc_01 = ds_acc[ds_acc['Timestamp']>=(start01-5)]\n",
    "                        ds_acc_01 = ds_acc_01[ds_acc_01['Timestamp']<=(end01+5)]\n",
    "                        chemin_dossier = \"Results/\"+part+\"/\"+str(test)+\"/\"\n",
    "                        nom_fichier = part+\"_mats_\"+out+\"_\"+str(test)+\".csv\"\n",
    "                        chemin_sauvegarde = chemin_dossier + nom_fichier\n",
    "                        ds_acc_01.to_csv(chemin_sauvegarde, index=False,header=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15843da",
   "metadata": {},
   "source": [
    "# Shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2231e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0              1   2   3     4   5   6   7   8     9     10    11  \\\n",
      "0          1  1698425226548  20  51 -1018  56  34  56 -76 -2728  5796  1527   \n",
      "1          2  1698425226585  20  51 -1018  58  35  54 -76 -2729  5795  1526   \n",
      "2          3  1698425226719  20  51 -1018  55  33  56 -75 -2730  5794  1528   \n",
      "3          4  1698425226802  20  51 -1017  54  35  55 -75 -2730  5794  1527   \n",
      "4          5  1698425226803  20  52 -1017  57  32  54 -76 -2731  5795  1525   \n",
      "...      ...            ...  ..  ..   ...  ..  ..  ..  ..   ...   ...   ...   \n",
      "88213  22710  1698427621851  14  31 -1018  62  49  49 -81 -3034  5811  1345   \n",
      "88214  22711  1698427621866  13  30 -1019  61  49  49 -82 -3034  5814  1396   \n",
      "88215  22712  1698427621889  13  30 -1018  62  46  49 -83 -3033  5816  1346   \n",
      "88216  22713  1698427621911  15  30 -1017  61  47  51 -82 -3033  5818  1316   \n",
      "88217  22714  1698427621926  14  29 -1019  64  50  48 -83 -3033  5821  1346   \n",
      "\n",
      "         12    13    14    15  \n",
      "0      1124  1601  2158  2228  \n",
      "1      1127  1597  2157  2227  \n",
      "2      1130  1597  2156  2226  \n",
      "3      1130  1598  2158  2227  \n",
      "4      1128  1597  2158  2227  \n",
      "...     ...   ...   ...   ...  \n",
      "88213   786  1601  2081  2134  \n",
      "88214   799  1624  2080  2124  \n",
      "88215   849  1595  2077  2122  \n",
      "88216   828  1582  2070  2123  \n",
      "88217   881  1545  2060  2112  \n",
      "\n",
      "[88218 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "file_shoes=pd.read_csv(\"Data/Mats_Shoes/DL_All_lf.csv\",header=None)\n",
    "print(file_shoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a8170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1698418026548\n",
      "1        1698418026585\n",
      "2        1698418026719\n",
      "3        1698418026802\n",
      "4        1698418026803\n",
      "             ...      \n",
      "88213    1698420421851\n",
      "88214    1698420421866\n",
      "88215    1698420421889\n",
      "88216    1698420421911\n",
      "88217    1698420421926\n",
      "Name: 1, Length: 88218, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(file_shoes[1]-7200000)#moins deux heures en timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2b622a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shoes = pd.read_excel('Data/Mats_Shoes/summarytable.xlsx', skiprows=range(1, 89), nrows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ab66e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pied=[\"lf\",\"rf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7356662",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in ts.iterrows():\n",
    "    timestamp_deb_ent=row['Start timestamp']\n",
    "    timestamp_deb = int(str(timestamp_deb_ent)[:-2])\n",
    "    timestamp_fin_ent=row['End timestamp']\n",
    "    timestamp_fin = int(str(timestamp_fin_ent)[:-2])\n",
    "    part=row['Participant']\n",
    "    test=row['Test Number']\n",
    "    fich=row['NomFichier2']\n",
    "    for p in pied:\n",
    "        if (part==\"DS\" or part==\"DL\"):\n",
    "            chemin_fichier_csv = \"Data/Mats_Shoes/\"+fich+\"_\"+p+\".csv\"\n",
    "            ds_acc = pd.read_csv(chemin_fichier_csv,header=None)\n",
    "            start01 = timestamp_deb\n",
    "            end01 = timestamp_fin\n",
    "            ds_acc_01 = ds_acc[ds_acc[1]-7200000>=(start01-5000)]\n",
    "            ds_acc_01 = ds_acc_01[ds_acc_01[1]-7200000<=(end01+5000)]\n",
    "            chemin_dossier = \"Results/\"+part+\"/\"+str(test)+\"/\"\n",
    "            nomfich=part+\"_shoes_\"+p+\"_\"+str(test)+\".csv\"\n",
    "            chemin_sauvegarde = chemin_dossier + nomfich\n",
    "            ds_acc_01.to_csv(chemin_sauvegarde, index=False,header=False)\n",
    "        else:\n",
    "            chemin_fichier_csv = \"Data/Mats_Shoes/\"+fich+\"_\"+p+\".csv\"\n",
    "            ds_acc = pd.read_csv(chemin_fichier_csv,header=None)\n",
    "            start01 = timestamp_deb\n",
    "            end01 = timestamp_fin\n",
    "            ds_acc_01 = ds_acc[ds_acc[1]-3600000>=(start01-5000)]\n",
    "            ds_acc_01 = ds_acc_01[ds_acc_01[1]-3600000<=(end01+5000)]\n",
    "            chemin_dossier = \"Results/\"+part+\"/\"+str(test)+\"/\"\n",
    "            nomfich=part+\"_shoes_\"+p+\"_\"+str(test)+\".csv\"\n",
    "            chemin_sauvegarde = chemin_dossier + nomfich\n",
    "            ds_acc_01.to_csv(chemin_sauvegarde, index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2ac75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
