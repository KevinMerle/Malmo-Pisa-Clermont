{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26056b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa905d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_csv('TS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b112f1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Test Number</th>\n",
       "      <th>Start timestamp</th>\n",
       "      <th>End timestamp</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Back</th>\n",
       "      <th>Msafety_acc</th>\n",
       "      <th>Msafety_ppg</th>\n",
       "      <th>Bangle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.698412e+12</td>\n",
       "      <td>1.698412e+12</td>\n",
       "      <td>testResults_Ds01_hand.json</td>\n",
       "      <td>testResults_Ds01.json</td>\n",
       "      <td>6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...</td>\n",
       "      <td>6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...</td>\n",
       "      <td>DS01.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DS</td>\n",
       "      <td>2</td>\n",
       "      <td>1.698412e+12</td>\n",
       "      <td>1.698412e+12</td>\n",
       "      <td>testResults_Ds02_hand.json</td>\n",
       "      <td>testResults_Ds02.json</td>\n",
       "      <td>6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...</td>\n",
       "      <td>6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...</td>\n",
       "      <td>DS02.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DS</td>\n",
       "      <td>3</td>\n",
       "      <td>1.698412e+12</td>\n",
       "      <td>1.698412e+12</td>\n",
       "      <td>testResults_Ds03_hand.json</td>\n",
       "      <td>testResults_Ds03.json</td>\n",
       "      <td>6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...</td>\n",
       "      <td>6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...</td>\n",
       "      <td>DS03.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DS</td>\n",
       "      <td>4</td>\n",
       "      <td>1.698412e+12</td>\n",
       "      <td>1.698412e+12</td>\n",
       "      <td>testResults_Ds04_hand.json</td>\n",
       "      <td>testResults_Ds04.json</td>\n",
       "      <td>6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...</td>\n",
       "      <td>6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...</td>\n",
       "      <td>DS04.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DS</td>\n",
       "      <td>5</td>\n",
       "      <td>1.698413e+12</td>\n",
       "      <td>1.698413e+12</td>\n",
       "      <td>testResults_Ds05_hand.json</td>\n",
       "      <td>testResults_Ds05.json</td>\n",
       "      <td>6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...</td>\n",
       "      <td>6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...</td>\n",
       "      <td>DS05.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant  Test Number  Start timestamp  End timestamp  \\\n",
       "0          DS            1     1.698412e+12   1.698412e+12   \n",
       "1          DS            2     1.698412e+12   1.698412e+12   \n",
       "2          DS            3     1.698412e+12   1.698412e+12   \n",
       "3          DS            4     1.698412e+12   1.698412e+12   \n",
       "4          DS            5     1.698413e+12   1.698413e+12   \n",
       "\n",
       "                         Hand                   Back  \\\n",
       "0  testResults_Ds01_hand.json  testResults_Ds01.json   \n",
       "1  testResults_Ds02_hand.json  testResults_Ds02.json   \n",
       "2  testResults_Ds03_hand.json  testResults_Ds03.json   \n",
       "3  testResults_Ds04_hand.json  testResults_Ds04.json   \n",
       "4  testResults_Ds05_hand.json  testResults_Ds05.json   \n",
       "\n",
       "                                         Msafety_acc  \\\n",
       "0  6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...   \n",
       "1  6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...   \n",
       "2  6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...   \n",
       "3  6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...   \n",
       "4  6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...   \n",
       "\n",
       "                                         Msafety_ppg     Bangle  \n",
       "0  6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...  DS01.json  \n",
       "1  6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...  DS02.json  \n",
       "2  6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...  DS03.json  \n",
       "3  6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...  DS04.json  \n",
       "4  6ba8ac15de_st1dby_2023-10-27_13_2023-10-27_17_...  DS05.json  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abd2b3",
   "metadata": {},
   "source": [
    "# MSAFETY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8434879",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = ['DS', 'DL', 'MB', 'RC', 'PB', 'LC']\n",
    "\n",
    "for p in participant :\n",
    "    time = ts[ts['Participant']==p]\n",
    "    time.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    msafety_acc = 'Data/'+p+'/msafety/'+time['Msafety_acc'][0]\n",
    "    acc = pd.read_csv(msafety_acc)\n",
    "    \n",
    "    msafety_ppg = 'Data/'+p+'/msafety/'+time['Msafety_ppg'][0]\n",
    "    ppg = pd.read_csv(msafety_ppg)\n",
    "    \n",
    "    for i in range(1,11):\n",
    "        start = time['Start timestamp'][i-1] - 5000\n",
    "        end = time['End timestamp'][i-1] + 5000\n",
    "        \n",
    "        acc_exp = acc[acc['ts(msec)']>=start]\n",
    "        acc_exp = acc_exp[acc_exp['ts(msec)']<=end]\n",
    "        \n",
    "        acc_exp = acc_exp.rename(columns={'ts(msec)': 'timestamp'})\n",
    "        acc_exp = acc_exp.rename(columns={'X': 'accGx'})\n",
    "        acc_exp = acc_exp.rename(columns={'Y': 'accGy'})\n",
    "        acc_exp = acc_exp.rename(columns={'Z': 'accGz'})\n",
    "        acc_exp['timestamp'] = acc_exp['timestamp']/1000\n",
    "        \n",
    "        ppg_exp = ppg[ppg['ts(msec)']>=start]\n",
    "        ppg_exp = ppg_exp[ppg_exp['ts(msec)']<=end]\n",
    "        \n",
    "        ppg_exp = ppg_exp.rename(columns={'ts(msec)': 'timestamp'})\n",
    "        ppg_exp = ppg_exp.rename(columns={'PPG': 'ppg'})\n",
    "        ppg_exp['timestamp'] = ppg_exp['timestamp']/1000\n",
    "        \n",
    "        path_acc = 'Results/'+p+'/'+str(i)+'/'+p+'_msafety_acc_'+str(i)+'.csv'\n",
    "        acc_exp.to_csv(path_acc, index=False)\n",
    "        \n",
    "        path_ppg = 'Results/'+p+'/'+str(i)+'/'+p+'_msafety_ppg_'+str(i)+'.csv'\n",
    "        ppg_exp.to_csv(path_ppg, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e34de9",
   "metadata": {},
   "source": [
    "# BANGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7859a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = ['DS', 'DL', 'MB', 'RC', 'PB', 'LC']\n",
    "\n",
    "for p in participant :\n",
    "    time = ts[ts['Participant']==p]\n",
    "    time.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    for i in range(1,11):\n",
    "        start = time['Start timestamp'][i-1] - 5000\n",
    "        end = time['End timestamp'][i-1] + 5000\n",
    "        \n",
    "        # Chemin vers le fichier JSON\n",
    "        json_file_path_bangle = 'Data/'+p+'/bangle/'+time['Bangle'][i-1]\n",
    "        \n",
    "        # Charger les données JSON\n",
    "        with open(json_file_path_bangle, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        # Créer un DataFrame pour chaque catégorie\n",
    "        df_accel = pd.DataFrame(data.get('accel', []))\n",
    "        df_compass = pd.DataFrame(data.get('compass', []))\n",
    "        df_pressure = pd.DataFrame(data.get('pressure', []))\n",
    "        df_steps = pd.DataFrame(data.get('steps', []))\n",
    "        df_hr = pd.DataFrame(data.get('hr',[]))\n",
    "        \n",
    "        # Transformation des colonne ms pour avoir des timestamp\n",
    "        date_string = data.get('startTs')\n",
    "        utc_time = datetime.fromisoformat(date_string.replace('Z', '+00:00'))\n",
    "        local_timezone = pytz.timezone('Europe/Paris')  \n",
    "        local_time = utc_time.astimezone(local_timezone)\n",
    "        timestamp = local_time.timestamp() * 1000 \n",
    "\n",
    "        def addTS(x):\n",
    "            return x + timestamp\n",
    "\n",
    "        if 'ms' in df_accel.columns :\n",
    "            df_accel['ms'] = df_accel['ms'].apply(addTS)\n",
    "        if 'ms' in df_compass.columns :\n",
    "            df_compass['ms'] = df_compass['ms'].apply(addTS)\n",
    "        if 'ms' in df_pressure.columns :\n",
    "            df_pressure['ms'] = df_pressure['ms'].apply(addTS)\n",
    "        if 'ms' in df_steps.columns :\n",
    "            df_steps['ms'] = df_steps['ms'].apply(addTS)\n",
    "        if 'ms' in df_hr.columns :\n",
    "            df_hr['ms'] = df_hr['ms'].apply(addTS)\n",
    "\n",
    "        # Couper les DF avec start et end\n",
    "        if 'ms' in df_accel.columns :\n",
    "            df_accel = df_accel[df_accel['ms']>=start]\n",
    "            df_accel = df_accel[df_accel['ms']<=end]\n",
    "            df_accel = df_accel.rename(columns={'ms': 'timestamp'})\n",
    "            df_accel = df_accel.rename(columns={'x': 'accGx'})\n",
    "            df_accel = df_accel.rename(columns={'y': 'accGy'})\n",
    "            df_accel = df_accel.rename(columns={'z': 'accGz'})\n",
    "            df_accel['timestamp'] = df_accel['timestamp']/1000\n",
    "        if 'ms' in df_compass.columns :\n",
    "            df_compass = df_compass[df_compass['ms']>=start]\n",
    "            df_compass = df_compass[df_compass['ms']<=end]\n",
    "            df_compass = df_compass.rename(columns={'ms': 'timestamp'})\n",
    "            df_compass = df_compass.rename(columns={'x': 'magnRawx'})\n",
    "            df_compass = df_compass.rename(columns={'y': 'magnRawy'})\n",
    "            df_compass = df_compass.rename(columns={'z': 'magnRawz'})\n",
    "            df_compass['timestamp'] = df_compass['timestamp']/1000\n",
    "        if 'ms' in df_steps.columns :\n",
    "            df_steps = df_steps[df_steps['ms']>=start]\n",
    "            df_steps = df_steps[df_steps['ms']<=end]\n",
    "            df_steps = df_steps.rename(columns={'ms': 'timestamp'})\n",
    "            df_steps['timestamp'] = df_steps['timestamp']/1000\n",
    "        if 'ms' in df_hr.columns :\n",
    "            df_hr = df_hr[df_hr['ms']>=start]\n",
    "            df_hr = df_hr[df_hr['ms']<=end]\n",
    "            df_hr = df_hr.rename(columns={'ms': 'timestamp'})\n",
    "            df_hr['timestamp'] = df_hr['timestamp']/1000\n",
    "\n",
    "        # Écrire chaque DataFrame dans un csv séparé\n",
    "        path_accel = 'Results/'+p+'/'+str(i)+'/'+p+'_bangle_accel_'+str(i)+'.csv'\n",
    "        df_accel.to_csv(path_accel, index=False)\n",
    "        \n",
    "        path_compass = 'Results/'+p+'/'+str(i)+'/'+p+'_bangle_compass_'+str(i)+'.csv'\n",
    "        df_compass.to_csv(path_compass, index=False)\n",
    "        \n",
    "        path_pressure = 'Results/'+p+'/'+str(i)+'/'+p+'_bangle_pressure_'+str(i)+'.csv'\n",
    "        df_pressure.to_csv(path_pressure, index=False)\n",
    "        \n",
    "        path_steps = 'Results/'+p+'/'+str(i)+'/'+p+'_bangle_steps_'+str(i)+'.csv'\n",
    "        df_steps.to_csv(path_steps, index=False)\n",
    "        \n",
    "        path_hr = 'Results/'+p+'/'+str(i)+'/'+p+'_bangle_hr_'+str(i)+'.csv'\n",
    "        df_hr.to_csv(path_hr, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc487b",
   "metadata": {},
   "source": [
    "# BACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335ca10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = ['DS', 'DL', 'MB', 'RC', 'PB', 'LC']\n",
    "\n",
    "for p in participant:\n",
    "    time = ts[ts['Participant'] == p]\n",
    "    time.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        start = time['Start timestamp'][i - 1] - 5000\n",
    "        end = time['End timestamp'][i - 1] + 5000\n",
    "\n",
    "        # Chemin vers le fichier JSON\n",
    "        json_file_path_back = 'Data/' + p + '/back/' + time['Back'][i - 1]\n",
    "        \n",
    "        # Charger les données JSON\n",
    "        if time['Back'][i - 1] != 'None':\n",
    "            with open(json_file_path_back, 'r') as json_file:\n",
    "                data = json.load(json_file)\n",
    "\n",
    "            # Créer un DataFrame pour chaque catégorie\n",
    "            df_motion = pd.DataFrame(data.get('motion', []))\n",
    "            df_orientation = pd.DataFrame(data.get('orientation', []))\n",
    "            df_heartRate = pd.DataFrame(data.get('heartRate', []))\n",
    "            df_cadence = pd.DataFrame(data.get('cadence', []))\n",
    "\n",
    "            # Transformation des colonnes ms pour avoir des timestamp\n",
    "            date_string = data.get('startTs')\n",
    "            utc_time = datetime.fromisoformat(date_string.replace('Z', '+00:00'))\n",
    "            local_timezone = pytz.timezone('Europe/Paris')\n",
    "            local_time = utc_time.astimezone(local_timezone)\n",
    "            timestamp = local_time.timestamp() * 1000\n",
    "\n",
    "            def addTS(x):\n",
    "                return x + timestamp\n",
    "\n",
    "            if 'msFromStart' in df_motion.columns:\n",
    "                df_motion['msFromStart'] = df_motion['msFromStart'].apply(addTS)\n",
    "            if 'msFromStart' in df_orientation.columns:\n",
    "                df_orientation['msFromStart'] = df_orientation['msFromStart'].apply(addTS)\n",
    "            if 'msFromStart' in df_heartRate.columns:\n",
    "                df_heartRate['msFromStart'] = df_heartRate['msFromStart'].apply(addTS)\n",
    "            if 'msFromStart' in df_cadence.columns:\n",
    "                df_cadence['msFromStart'] = df_cadence['msFromStart'].apply(addTS)\n",
    "\n",
    "            # Couper les DF avec start et end\n",
    "            if 'msFromStart' in df_motion.columns:\n",
    "                df_motion = df_motion[df_motion['msFromStart'] >= start]\n",
    "                df_motion = df_motion[df_motion['msFromStart'] <= end]\n",
    "            if 'msFromStart' in df_orientation.columns:\n",
    "                df_orientation = df_orientation[df_orientation['msFromStart'] >= start]\n",
    "                df_orientation = df_orientation[df_orientation['msFromStart'] <= end]\n",
    "            if 'msFromStart' in df_heartRate.columns:\n",
    "                df_heartRate = df_heartRate[df_heartRate['msFromStart'] >= start]\n",
    "                df_heartRate = df_heartRate[df_heartRate['msFromStart'] <= end]\n",
    "            if 'msFromStart' in df_cadence.columns:\n",
    "                df_cadence = df_cadence[df_cadence['msFromStart'] >= start]\n",
    "                df_cadence = df_cadence[df_cadence['msFromStart'] <= end]\n",
    "\n",
    "            # Séparer la colonne 'acc' en 'accx', 'accy', 'accz'\n",
    "            if 'acc' in df_motion.columns:\n",
    "                df_motion['accx'] = df_motion['acc'].apply(lambda x: x['x'])\n",
    "                df_motion['accy'] = df_motion['acc'].apply(lambda x: x['y'])\n",
    "                df_motion['accz'] = df_motion['acc'].apply(lambda x: x['z'])\n",
    "                df_motion.drop(columns=['acc'], inplace=True)\n",
    "                \n",
    "             # Séparer la colonne 'accG' en 'accGx', 'accGy', 'accGz'\n",
    "            if 'accG' in df_motion.columns:\n",
    "                df_motion['accGx'] = df_motion['accG'].apply(lambda x: x['x'])\n",
    "                df_motion['accGy'] = df_motion['accG'].apply(lambda x: x['y'])\n",
    "                df_motion['accGz'] = df_motion['accG'].apply(lambda x: x['z'])\n",
    "                df_motion.drop(columns=['accG'], inplace=True)\n",
    "                \n",
    "            # Séparer la colonne 'rotRate' en 'alpha', 'beta', 'gamma'\n",
    "            if 'rotRate' in df_motion.columns:\n",
    "                df_motion['alpha'] = df_motion['rotRate'].apply(lambda x: x['alpha'])\n",
    "                df_motion['beta'] = df_motion['rotRate'].apply(lambda x: x['beta'])\n",
    "                df_motion['gamma'] = df_motion['rotRate'].apply(lambda x: x['gamma'])\n",
    "                df_motion.drop(columns=['rotRate'], inplace=True)\n",
    "                \n",
    "            # Modifications des noms de colonnes\n",
    "            if 'msFromStart' in df_motion.columns :\n",
    "                df_motion = df_motion.rename(columns={'msFromStart': 'timestamp'})\n",
    "                df_motion['timestamp'] = df_motion['timestamp']/1000\n",
    "            \n",
    "            if 'msFromStart' in df_orientation.columns :\n",
    "                df_orientation = df_orientation.rename(columns={'msFromStart': 'timestamp'})\n",
    "                df_orientation['timestamp'] = df_orientation['timestamp']/1000\n",
    "            \n",
    "            if 'msFromStart' in df_cadence.columns :\n",
    "                df_cadence = df_cadence.rename(columns={'msFromStart': 'timestamp'})\n",
    "                df_cadence['timestamp'] = df_cadence['timestamp']/1000\n",
    "                df_cadence = df_cadence[['timestamp', 'isRunning', 'instantaneousSpeed', 'instantaneousCadence', 'instantaneousStrideLength', 'totalDistance']]\n",
    "            \n",
    "            # Écrire chaque DataFrame dans un fichier csv séparé\n",
    "            directory = 'Results/' + p + '/' + str(i) + '/'\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "            df_motion.to_csv(directory + p + '_back_motion_' + str(i) + '.csv', index=False)\n",
    "            df_orientation.to_csv(directory + p + '_back_orientation_' + str(i) + '.csv', index=False)\n",
    "            df_heartRate.to_csv(directory + p + '_back_heartRate_' + str(i) + '.csv', index=False)\n",
    "            df_cadence.to_csv(directory + p + '_back_cadence_' + str(i) + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f987041",
   "metadata": {},
   "source": [
    "# HAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "514ec679",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = ['DS', 'DL', 'MB', 'RC', 'PB', 'LC']\n",
    "\n",
    "for p in participant:\n",
    "    time = ts[ts['Participant'] == p]\n",
    "    time.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    for i in range(1, 11):\n",
    "        start = time['Start timestamp'][i-1] \n",
    "        end = time['End timestamp'][i-1] \n",
    "        \n",
    "        # Chemin vers le fichier JSON Hand\n",
    "        json_file_path_hand = f'Data/{p}/hand/{time[\"Hand\"][i-1]}'\n",
    "        \n",
    "        # Vérifier si le fichier JSON Hand existe\n",
    "        if os.path.exists(json_file_path_hand):\n",
    "            # Charger les données JSON Hand\n",
    "            with open(json_file_path_hand, 'r') as json_file:\n",
    "                data = json.load(json_file)\n",
    "\n",
    "            # Créer un DataFrame pour chaque catégorie\n",
    "            df_motion = pd.DataFrame(data.get('motion', []))\n",
    "            df_orientation = pd.DataFrame(data.get('orientation', []))\n",
    "            df_heart_rate = pd.DataFrame(data.get('heartRate', []))\n",
    "            df_cadence = pd.DataFrame(data.get('cadence', []))\n",
    "            \n",
    "            # Séparer la colonne 'acc' en 'accx', 'accy', 'accz'\n",
    "            if 'acc' in df_motion.columns:\n",
    "                df_motion['accx'] = df_motion['acc'].apply(lambda x: x['x'])\n",
    "                df_motion['accy'] = df_motion['acc'].apply(lambda x: x['y'])\n",
    "                df_motion['accz'] = df_motion['acc'].apply(lambda x: x['z'])\n",
    "                df_motion.drop(columns=['acc'], inplace=True)\n",
    "                \n",
    "             # Séparer la colonne 'accG' en 'accx', 'accy', 'accz'\n",
    "            if 'accG' in df_motion.columns:\n",
    "                df_motion['accGx'] = df_motion['accG'].apply(lambda x: x['x'])\n",
    "                df_motion['accGy'] = df_motion['accG'].apply(lambda x: x['y'])\n",
    "                df_motion['accGz'] = df_motion['accG'].apply(lambda x: x['z'])\n",
    "                df_motion.drop(columns=['accG'], inplace=True)\n",
    "                \n",
    "            # Séparer la colonne 'rotRate' en 'alpha', 'beta', 'gamma'\n",
    "            if 'rotRate' in df_motion.columns:\n",
    "                df_motion['alpha'] = df_motion['rotRate'].apply(lambda x: x['alpha'])\n",
    "                df_motion['beta'] = df_motion['rotRate'].apply(lambda x: x['beta'])\n",
    "                df_motion['gamma'] = df_motion['rotRate'].apply(lambda x: x['gamma'])\n",
    "                df_motion.drop(columns=['rotRate'], inplace=True)\n",
    "                \n",
    "            # Transformation des colonnes ms pour avoir des timestamp\n",
    "            def addTS(x):\n",
    "                return x + start\n",
    "\n",
    "            if 'msFromStart' in df_motion.columns:\n",
    "                df_motion['msFromStart'] = df_motion['msFromStart'].apply(addTS)\n",
    "            if 'msFromStart' in df_orientation.columns:\n",
    "                df_orientation['msFromStart'] = df_orientation['msFromStart'].apply(addTS)\n",
    "            if 'msFromStart' in df_heartRate.columns:\n",
    "                df_heartRate['msFromStart'] = df_heartRate['msFromStart'].apply(addTS)\n",
    "            if 'msFromStart' in df_cadence.columns:\n",
    "                df_cadence['msFromStart'] = df_cadence['msFromStart'].apply(addTS)\n",
    "            \n",
    "            # Modifications noms de colonnes\n",
    "            if 'msFromStart' in df_motion.columns :\n",
    "                df_motion = df_motion.rename(columns={'msFromStart': 'timestamp'})\n",
    "                df_motion['timestamp'] = df_motion['timestamp']/1000\n",
    "            \n",
    "            if 'msFromStart' in df_orientation.columns :\n",
    "                df_orientation = df_orientation.rename(columns={'msFromStart': 'timestamp'})\n",
    "                df_orientation['timestamp'] = df_orientation['timestamp']/1000\n",
    "            \n",
    "            if 'msFromStart' in df_cadence.columns :\n",
    "                df_cadence = df_cadence.rename(columns={'msFromStart': 'timestamp'})\n",
    "                df_cadence['timestamp'] = df_cadence['timestamp']/1000\n",
    "                df_cadence = df_cadence[['timestamp', 'isRunning', 'instantaneousSpeed', 'instantaneousCadence', 'instantaneousStrideLength', 'totalDistance']]\n",
    "                \n",
    "            if 'msFromStart' in df_heartRate.columns :\n",
    "                df_heartRate = df_heartRate.rename(columns={'msFromStart': 'timestamp'})\n",
    "                df_heartRate['timestamp'] = df_heartRate['timestamp']/1000\n",
    "            \n",
    "            # Écrire chaque DataFrame dans un fichier csv séparé\n",
    "            directory = 'Results/' + p + '/' + str(i) + '/'\n",
    "\n",
    "            df_motion.to_csv(directory + p + '_hand_motion_' + str(i) + '.csv', index=False)\n",
    "            df_orientation.to_csv(directory + p + '_hand_orientation_' + str(i) + '.csv', index=False)\n",
    "            df_heartRate.to_csv(directory + p + '_hand_heartRate_' + str(i) + '.csv', index=False)\n",
    "            df_cadence.to_csv(directory + p + '_hand_cadence_' + str(i) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd07d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
